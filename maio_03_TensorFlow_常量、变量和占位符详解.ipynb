{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 支持以下三种类型的张量：\n",
    "常量：常量是其值不能改变的张量。  \n",
    "变量：当一个量在会话中的值需要更新时，使用变量来表示。例如，在神经网络中，权重需要在训练期间更新，\n",
    "    可以通过将权重声明为变量来实现。变量在使用前需要被显示初始化。另外需要注意的是，常量存储在计算图的定义中，\n",
    "    每次加载图时都会加载相关变量。换句话说，它们是占用内存的。另一方面，变量又是分开存储的。它们可以存储在参数服务器上。  \n",
    "占位符：用于将值输入 TensorFlow 图中。它们可以和 feed_dict 一起使用来输入数据。在训练神经网络时，它们通常用于提供新\n",
    "    的训练样本。在会话中运行计算图时，可以为占位符赋值。这样在构建一个计算图时不需要真正地输入数据。\n",
    "    需要注意的是，占位符不包含任何数据，因此不需要初始化它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 声明一个标量常量：\n",
    "t_1 = tf.constant(4)\n",
    "print(t_1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2]\n"
     ]
    }
   ],
   "source": [
    "# 一个形如 [1，3] 的常量向量可以用如下代码声明：\n",
    "t_2 = tf.constant([4, 3, 2]) # 就是类似一个数组3个元素\n",
    "t_2.get_shape() #TensorShape([Dimension(3)])\n",
    "print(t_2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 要创建一个所有元素为零的张量，可以使用 tf.zeros() 函数。这个语句可以创建一个形如 [M，N] 的零元素矩阵，\n",
    "# 数据类型（dtype）可以是 int32、float32 等：\n",
    "zero_t = tf.zeros([2, 3], tf.int32) # 2行3列\n",
    "print(zero_t.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 还可以创建与现有 Numpy 数组或张量常量具有相同形状的张量常量，如下所示：\n",
    "tf.zeros_like(t_2) #返回结果和上面的t_2一样\n",
    "print(tf.zeros_like(t_2).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "tf.ones_like(t_2) #返回结果和上面的t_2形状一样，但是值都是1\n",
    "print(tf.ones_like(t_2).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 创建一个所有元素都设为 1 的张量。下面的语句即创建一个形如 [M，N]、元素均为 1 的矩阵： tf.ones([M,N]dtype)\n",
    "ones_t = tf.ones([2,3],tf.int32) # 返回一个 2x3 矩阵 值全为1:[[1 1 1],[1 1 1]]\n",
    "print(ones_t.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在一定范围内生成一个从初值到终值等差排布的序列：# tf.linspace(start,stop,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.   2.75 3.5  4.25 5.  ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 相应的值为 (stop-start)/(num-1)。例如：\n",
    "range_t = tf.linspace(2.0,5.0,5) # 返回:[2. 2.75 3.5 4.25 5.]\n",
    "print(range_t.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从开始（默认值=0）生成一个数字序列，增量为 delta（默认值=1），直到终值（但不包括终值）：tf.range(start,limit,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "range_t = tf.range(10)\n",
    "print(range_t.eval())\n",
    "range_t1 = tf.range(1,10,2)\n",
    "print(range_t1.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 允许创建具有不同分布的随机张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_random1: [[ 0.25347447  5.37991     1.9527606 ]\n",
      " [-1.5376031   1.2588985   2.8478067 ]]\n",
      "t_random2: [[-0.87326276  1.689955   -0.02361972 -1.7688016  -0.37055078]]\n",
      "t_random3: [[2.54461   3.6963658 2.7051091]\n",
      " [2.0085006 3.8445983 3.5426888]]\n"
     ]
    }
   ],
   "source": [
    "# 1、使用以下语句创建一个具有一定均值（默认值=0.0）和标准差（默认值=1.0）、形状为 [M，N] 的正态分布随机数组：\n",
    "t_random1 = tf.random_normal([2,3],mean=2.0, stddev=4.0,seed=12) # mean:均值  stddev:标准差 seed:随机数种子\n",
    "print(\"t_random1:\",t_random1.eval())\n",
    "\n",
    "# 2、创建一个具有一定均值（默认值=0.0）和标准差（默认值=1.0）、形状为 [M，N] 的截尾正态分布随机数组：\n",
    "t_random2 = tf.random_normal([1,5],stddev=2.0,seed=12)\n",
    "print(\"t_random2:\",t_random2.eval())\n",
    "\n",
    "# 3、要在种子的 [minval（default=0），maxval] 范围内创建形状为 [M，N] 的给定伽马分布随机数组，请执行如下语句：\n",
    "t_random3 = tf.random_uniform([2,3],maxval=4,seed=12)# 表示生产的数要在maxval以内\n",
    "print(\"t_random3:\",t_random3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[[-4.349812   -3.0933433 ]\n",
      " [ 7.594398    0.80044365]]\n"
     ]
    }
   ],
   "source": [
    "# 4、要将给定的张量随机裁剪为指定的大小，使用以下语句：\n",
    "t_random4=tf.random_crop(t_random1,[2,2])\n",
    "# 这里，t_random1 是一个已经定义好的张量。这将导致随机从张量 t_random1 中裁剪出一个大小为 [2,2] 的张量。注意要截取的大小不能超过原来的大小\n",
    "print(t_random4.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0348392   0.9963404   6.651938  ]\n",
      " [-0.54157615 -6.130026    8.686395  ]]\n"
     ]
    }
   ],
   "source": [
    "# 很多时候需要以随机的顺序来呈现训练样本，可以使用 tf.random_shuffle() 来沿着它的第一维随机排列张量。如果 t_random1 是想要重新排序的张量，\n",
    "# 使用下面的代码：\n",
    "t_random1=tf.random_shuffle(t_random1)\n",
    "\n",
    "print(t_random1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5、随机生成的张量受初始种子值的影响。要在多次运行或会话中获得相同的随机数，应该将种子设置为一个常数值。当使用大量的随机张量时，\n",
    "# 可以使用 tf.set_random_seed() 来为所有随机产生的张量设置种子。以下命令将所有会话的随机张量的种子设置为 54：\n",
    "tf.set_random_seed(54.3) # TIP：种子只能有整数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它们通过使用变量类来创建。变量的定义还包括应该初始化的常量/随机值。下面的代码中创建了两个不同的张量变量 t_a 和 t_b。两者将被初始化为形状为 [50，50] 的随机均匀分布，最小值=0，最大值=10："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4069426  5.547518   4.030776   ... 2.6850677  0.04653335 2.6041317 ]\n",
      " [9.87289    4.8271074  5.89602    ... 0.2995813  8.613447   7.001593  ]\n",
      " [3.0946112  8.5887     9.890547   ... 3.9138663  6.9175854  6.8808675 ]\n",
      " ...\n",
      " [8.343704   3.8824725  1.7797065  ... 3.9513707  7.3586454  0.7811904 ]\n",
      " [1.6197157  7.5581017  5.452465   ... 2.2101688  9.297016   1.9363952 ]\n",
      " [1.4558351  9.001893   6.835965   ... 3.9646196  2.512865   2.3548222 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(50, 50) dtype=float32_ref>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_t=tf.random_uniform([50,50],0,10,seed=0)\n",
    "t_a=tf.Variable(rand_t)\n",
    "t_b=tf.Variable(rand_t)\n",
    "\n",
    "# 变量通常在神经网络中表示权重和偏置。\n",
    "\n",
    "print(rand_t.eval())\n",
    "t_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码中定义了两个变量的权重和偏置。权重变量使用正态分布随机初始化，均值为 0，标准差为 2，权重大小为 100×100。偏置由 100 个元素组成，每个元素初始化为 0。在这里也使用了可选参数名以给计算图中定义的变量命名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([100,100],stddev=2))\n",
    "bias = tf.Variable(tf.zeros([100],name='biases'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面的例子中，都是利用一些常量来初始化变量，也可以指定一个变量来初始化另一个变量。下面的语句将利用前面定义的权重来初始化 weight2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2 = tf.Variable(weights.initialized_value(),name='w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量的定义将指定变量如何被初始化，但是必须显式初始化所有的声明变量。在计算图的定义中通过声明初始化操作对象来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3755898 ,  2.8221767 ,  0.37220478, ...,  3.1763194 ,\n",
       "         1.5437793 ,  4.5248075 ],\n",
       "       [ 2.17658   , -0.7739357 ,  1.2511246 , ...,  1.415239  ,\n",
       "        -1.3329984 ,  0.23394133],\n",
       "       [ 1.7612513 , -3.6240215 ,  0.48418263, ..., -4.6162434 ,\n",
       "        -0.5223486 , -0.19329005],\n",
       "       ...,\n",
       "       [-1.4084527 ,  1.032459  , -1.1640867 , ..., -1.382005  ,\n",
       "         0.02933717,  1.401295  ],\n",
       "       [ 0.48603812,  1.2666049 , -1.7372373 , ...,  1.3162826 ,\n",
       "        -1.3466527 ,  0.60307276],\n",
       "       [-0.81181246,  1.2696763 , -2.5834663 , ..., -2.2741408 ,\n",
       "         1.4403521 ,  1.8669788 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_op = tf.global_variables_initializer()\n",
    "sess.run(initial_op)\n",
    "weights.eval()  # 对于变量需要执行初始化操作，然后才能执行 eval() 方法输出结果\n",
    "bias.eval()\n",
    "weight2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个变量也可以在运行图中单独使用 tf.Variable.initializer 来初始化：`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = tf.Variable(tf.zeros([100,100]))\n",
    "sess.run(bias.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存变量：使用 Saver 类来保存变量，定义一个 Saver 操作对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 占位符\n",
    "介绍完常量和变量之后，我们来讲解最重要的元素——占位符，它们用于将数据提供给计算图。可以使用以下方法定义一个占位符："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtype 定占位符的数据类型，并且必须在声明占位符时指定。在这里，为 x 定义一个占位符并计算 y=2*x，使用 feed_dict 输入一个随机的 4×5 矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.983776  2.6391926 5.12687   8.030235  7.552071 ]\n",
      " [3.6717763 9.175649  3.842248  3.725483  3.904914 ]\n",
      " [6.0162964 1.3480339 7.7283125 3.2368517 8.831539 ]\n",
      " [6.0324645 8.558892  1.6593275 4.1518764 8.918901 ]]\n",
      "[[ 7.967552   5.278385  10.25374   16.06047   15.104142 ]\n",
      " [ 7.3435526 18.351297   7.684496   7.450966   7.809828 ]\n",
      " [12.032593   2.6960678 15.456625   6.4737034 17.663078 ]\n",
      " [12.064929  17.117785   3.318655   8.303753  17.837803 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder('float') # 定义一个 float 类型的占位符\n",
    "y = 2 * x\n",
    "data = tf.random_uniform([4,5],10) # 定义一个4行5列最大值为10的伽马分布随机数\n",
    "x_data = sess.run(data)\n",
    "print(sess.run(y,feed_dict={x:x_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解读分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，所有常量、变量和占位符将在代码的计算图部分中定义。如果在定义部分使用 print 语句，只会得到有关张量类型的信息，而不是它的值。\n",
    "为了得到相关的值，需要创建会话图并对需要提取的张量显式使用运行命令，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(t_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拓展阅读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多时候需要大规模的常量张量对象；在这种情况下，为了优化内存，最好将它们声明为一个可训练标志设置为 False 的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_large = tf.Varible(large_array,trainable = False) # trainable表示在训练时不训练该变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 被设计成与 Numpy 配合运行，因此所有的 TensorFlow 数据类型都是基于 Numpy 的。使用 tf.convert_to_tensor() 可以将给定的值转换为张量类型，并将其与 TensorFlow 函数和运算符一起使用。该函数接受 Numpy 数组、Python 列表和 Python 标量，并允许与张量对象互操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下表列出了 TensorFlow 支持的常见的数据类型：\n",
    "![](http://c.biancheng.net/uploads/allimg/190107/2-1Z10G4153M25.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，与 Python/Numpy 序列不同，TensorFlow 序列不可迭代。试试下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-07d59a9b5aec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-07d59a9b5aec>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for i in tf.range(10)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close() # 最后不要忘记关闭会话 Session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
