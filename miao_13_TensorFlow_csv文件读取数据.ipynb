{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow csv文件读取数据（代码实现）详解\n",
    "大多数人了解 Pandas 及其在处理[大数据](http://c.biancheng.net/big_data/)文件方面的实用性。TensorFlow 提供了读取这种文件的方法。\n",
    "\n",
    "前面章节中，介绍了如何在 TensorFlow 中读取文件，本节将重点介绍如何从 CSV 文件中读取数据并在训练之前对数据进行预处理。\n",
    "\n",
    "本节将采用哈里森和鲁宾菲尔德于 1978 年收集的波士顿房价数据集（http://lib.stat.cmu.edu/datasets/boston ），该数据集包括 506 个样本场景，每个房屋含 14 个特征：\n",
    "1. CRIM：城镇人均犯罪率\n",
    "2. ZN：占地 25000 平方英尺（1 英尺=0.3048 米）以上的住宅用地比例\n",
    "3. INDUS：每个城镇的非零售商业用地比例\n",
    "4. CHAS：查尔斯河（Charles River）变量（若土地位于河流边界，则为 1；否则为 0）\n",
    "5. NOX：一氧化氮浓度（每千万）\n",
    "6. RM：每个寓所的平均房间数量\n",
    "7. AGE：1940 年以前建成的自住单元比例\n",
    "8. DIS：到 5 个波士顿就业中心的加权距离\n",
    "9. RAD：径向高速公路可达性指数\n",
    "10. TAX：每万美元的全价值物业税税率\n",
    "11. PTRATIO：镇小学老师比例\n",
    "12. B：1000(Bk-0.63)2，其中 Bk 是城镇黑人的比例\n",
    "13. LSTAT：低地位人口的百分比\n",
    "14. MEDV：1000 美元自有住房的中位值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow读取csv文件过程\n",
    "1. 导入所需的模块并声明全局变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 全局变量\n",
    "DATA_FILE = '../Database/boston_housing.csv'\n",
    "BATCH_SIZE = 10 # 批次的大小\n",
    "NUM_FEATURES = 14 # 特征的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义一个将文件名作为参数的函数，并返回大小等于 BATCH_SIZE 的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(filename):\n",
    "    \"\"\" 生成器张量批量Batch_SIZE批量。\n",
    "    Args: 字符串张量 要从中读取数据的文件名\n",
    "    Returns: feature_batch和label_batch\n",
    "    \"\"\"\n",
    "    # 3.定义 f_queue(文件队列) 和 reader 为文件名：\n",
    "    f_queue = tf.train.string_input_producer(filename) # 使用tf.train.string_input_producer创建文件名队列\n",
    "    # reader对象从文件名队列中读取数据\n",
    "    reader = tf.TextLineReader(skip_header_lines=1) # skips the first line 因为第一行为标签\n",
    "    _, value = reader.read(f_queue)\n",
    "    print(\"_:\",_,\"\\nvalue:\",value)\n",
    "    \n",
    "    # 4.这里指定要使用的数据以防数据丢失。对 .csv 解码并选择需要的特征。例如，选择 RM、PTRATIO 和 LSTAT 特征：\n",
    "    record_defaults = [[0.0] for _ in range(NUM_FEATURES)]\n",
    "    data = tf.decode_csv(value,record_defaults=record_defaults)\n",
    "    print(\"data:\",data,\"\\n\")\n",
    "    features = tf.stack(tf.gather_nd(data,[[5],[10],[12]]))\n",
    "    label = data[-1]\n",
    "    \n",
    "    # 5.定义参数来生成批并使用 tf.train.shuffle_batch() 来随机重新排列张量。该函数返回张量 feature_batch 和 label_batch：\n",
    "    # minimum number elements in the queue after a dequeue\n",
    "    min_after_dequeue = 10 * BATCH_SIZE\n",
    "    # the maximum number of elements in the queue (队列中的最大元素数)\n",
    "    capacity = 20 * BATCH_SIZE\n",
    "    \n",
    "    \n",
    "    # shuffile the data to generate BATCH_SIZE sample pairs(将数据移动以生成BATCH_SIZE样本对)\n",
    "    feature_batch,label_batch = tf.train.shuffle_batch([features,label],\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       capacity=capacity,\n",
    "                                                       min_after_dequeue=min_after_dequeue)\n",
    "    return feature_batch,label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 这里定义了另一个函数在会话中生成批："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(feature_batch,label_batch):\n",
    "    with tf.Session() as sess:\n",
    "        # intialize the queue threads (初始化队列线程) \n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord) # 启动填充为文件队列的线程\n",
    "        for _ in range(5): # Generate 5 batches\n",
    "            features, labels = sess.run([feature_batch,label_batch])\n",
    "            print(features, 'HI')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 使用这两个函数得到批中的数据。这里，仅打印数据；在学习训练时，将在这里执行优化步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0808 18:18:32.234528 32824 deprecation.py:323] From <ipython-input-2-eaf54aa1157c>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0808 18:18:32.278502 32824 deprecation.py:323] From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0808 18:18:32.281502 32824 deprecation.py:323] From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0808 18:18:32.289500 32824 deprecation.py:323] From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0808 18:18:32.294496 32824 deprecation.py:323] From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0808 18:18:32.306486 32824 deprecation.py:323] From <ipython-input-2-eaf54aa1157c>:8: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "W0808 18:18:32.356457 32824 deprecation.py:323] From <ipython-input-2-eaf54aa1157c>:30: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "W0808 18:18:32.397612 32824 deprecation.py:323] From <ipython-input-3-e5419284f189>:5: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_: Tensor(\"ReaderReadV2:0\", shape=(), dtype=string) \n",
      "value: Tensor(\"ReaderReadV2:1\", shape=(), dtype=string)\n",
      "data: [<tf.Tensor 'DecodeCSV:0' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:4' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:5' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:6' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:7' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:8' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:9' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:10' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:11' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:12' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:13' shape=() dtype=float32>] \n",
      "\n",
      "[[ 5.594 18.9   13.09 ]\n",
      " [ 7.079 17.8    5.7  ]\n",
      " [ 6.096 21.    20.34 ]\n",
      " [ 6.575 15.3    4.98 ]\n",
      " [ 5.787 16.1   10.24 ]\n",
      " [ 6.249 18.2   10.59 ]\n",
      " [ 6.121 18.5    8.44 ]\n",
      " [ 5.851 20.9   16.47 ]\n",
      " [ 6.405 17.8    8.2  ]\n",
      " [ 5.713 21.    22.6  ]] HI\n",
      "[[ 5.631 15.2   29.93 ]\n",
      " [ 8.069 18.     4.21 ]\n",
      " [ 6.115 16.8    9.43 ]\n",
      " [ 6.069 17.9    9.55 ]\n",
      " [ 6.279 18.7   11.97 ]\n",
      " [ 5.841 19.2   11.41 ]\n",
      " [ 6.145 19.7    6.86 ]\n",
      " [ 6.383 17.3    5.77 ]\n",
      " [ 6.998 18.7    2.94 ]\n",
      " [ 6.176 17.8   12.04 ]] HI\n",
      "[[ 6.195 20.9   13.   ]\n",
      " [ 6.417 19.2    6.72 ]\n",
      " [ 6.169 17.9    5.81 ]\n",
      " [ 6.674 21.    11.98 ]\n",
      " [ 5.599 21.    16.51 ]\n",
      " [ 5.961 19.2    9.88 ]\n",
      " [ 6.092 17.8   17.09 ]\n",
      " [ 7.007 17.8    5.5  ]\n",
      " [ 5.836 20.9   18.66 ]\n",
      " [ 6.021 17.8   10.3  ]] HI\n",
      "[[ 6.03  17.9   18.8  ]\n",
      " [ 6.142 21.    18.72 ]\n",
      " [ 5.927 19.7    9.22 ]\n",
      " [ 5.813 21.    14.81 ]\n",
      " [ 6.458 21.2   12.6  ]\n",
      " [ 5.913 17.8   16.21 ]\n",
      " [ 5.399 17.9   30.81 ]\n",
      " [ 6.595 18.3    4.32 ]\n",
      " [ 5.822 21.2   15.03 ]\n",
      " [ 6.495 21.    12.8  ]] HI\n",
      "[[ 6.172 15.2   19.15 ]\n",
      " [ 5.813 21.    19.88 ]\n",
      " [ 7.024 18.3    1.98 ]\n",
      " [ 5.727 21.    11.28 ]\n",
      " [ 6.232 18.7   12.34 ]\n",
      " [ 6.072 21.    13.04 ]\n",
      " [ 5.456 21.    11.69 ]\n",
      " [ 5.935 21.     6.58 ]\n",
      " [ 5.928 17.8   15.76 ]\n",
      " [ 6.335 21.2   16.96 ]] HI\n"
     ]
    }
   ],
   "source": [
    "feature_batch, label_batch = data_generator([DATA_FILE])\n",
    "generate_data(feature_batch,label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow csv数据预处理\n",
    "用前面章节提到的 TensorFlow 控制操作和张量来对数据进行预处理。例如，对于波士顿房价的情况，大约有 16 个数据行的 MEDV 是 50.0。在大多数情况下，这些数据点包含缺失或删减的值，因此建议不要考虑用这些数据训练。可以使用下面的代码在训练数据集中删除它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-efa8261e4b30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_FEATURES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "condition = tf.equal(data[13],tf.constant(50.0))\n",
    "data = tf.where(condition, tf.zeros(NUM_FEATURES),data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里定义了一个张量布尔条件，若 MEDV 等于 50.0 则为真。如果条件为真则可使用 TensorFlow tf.where() 操作赋为零值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
