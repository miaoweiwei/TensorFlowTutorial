{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow实现多元线性回归（超详细）\n",
    "在 TensorFlow 实现简单线性回归的基础上，可通过在权重和占位符的声明中稍作修改来对相同的数据进行多元线性回归。\n",
    "\n",
    "在多元线性回归的情况下，由于每个特征具有不同的值范围，归一化变得至关重要。这里是波士顿房价数据集的多重线性回归的代码，使用 13 个输入特征。\n",
    "\n",
    "波士顿房价数据集可从http://lib.stat.cmu.edu/datasets/boston处获取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多元线性回归的具体实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 导入需要的所有软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 因为各特征的数据范围不同，需要归一化特征数据。为此定义一个归一化函数。另外，这里添加一个额外的固定输入值将权重和偏置结合起来。为此定义函数 append_bias_reshape()。该技巧有时可有效简化编程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    \"\"\"Normalizes the array X,规范化数组X.\"\"\"\n",
    "    mean = np.mean(X)\n",
    "    #     std = np.std(arr,axis=0)  # axis=0计算每一列的标准差\n",
    "    #     std = np.std(arr,axis=1)  # 计算每一行的标准差\n",
    "    std = np.std(X)  # 计算全局标准差\n",
    "    X = (X - mean) / std\n",
    "    return X\n",
    "\n",
    "\n",
    "def append_bias_reshape(features, labels):\n",
    "    \"\"\"给数据添加偏执\"\"\"\n",
    "    m = features.shape[0]  # 行数\n",
    "    n = features.shape[1]  # 列数\n",
    "    x = np.reshape(np.c_[np.ones(m), features], [m, n + 1]) # 把添加过偏执的特征指定形状[m, n + 1]\n",
    "    y = np.reshape(labels, [m, 1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1: [[1 2 3 7 8 9]\n",
      " [4 5 6 3 2 1]]\n",
      "b2: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]\n",
      " [3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# np.c_ 和 np.r_ 的作用\n",
    "a1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a2 = np.array([[7, 8, 9], [3, 2, 1]])\n",
    "b1 = np.c_[a1, a2]  # 把两个矩阵的列对齐\n",
    "print('b1:', b1)\n",
    "b2 = np.r_[a1, a2]  # 把两个矩阵的行对齐\n",
    "print('b2:', b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 现在使用 TensorFlow contrib 数据集加载波士顿房价数据集，并将其划分为 X_train 和 Y_train。注意到 X_train 包含所需要的特征。可以选择在这里对数据进行归一化处理，也可以添加偏置并对网络数据重构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date\n",
    "boston = tf.contrib.learn.datasets.load_dataset('boston')  # 前十三列都是特征， 最后一个是标签\n",
    "# 数据集的第5列房间数量（RM），最后一列为标签（MEDV）给出的房价\n",
    "X_train, Y_train = boston.data, boston.target\n",
    "X_train = normalize(X_train)  # 归一化\n",
    "X_train, Y_train = append_bias_reshape(X_train, Y_train)\n",
    "m = len(X_train)  # 培训示例数量\n",
    "n = 13 + 1  # 特征的数量 + 偏执"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 为训练数据声明 TensorFlow 占位符。观测占位符 X 的形状变化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for the Training Data\n",
    "X = tf.placeholder(tf.float32, name='X',\n",
    "                   shape=[m, n])  # 输入数据的形状[m，n] m 为数据的数量 n 为一个数据的特征\n",
    "Y = tf.placeholder(tf.float32, name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 为权重和偏置创建 TensorFlow 变量。通过随机数初始化权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for coefficients 系数变量\n",
    "w = tf.Variable(tf.random_normal([n, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 定义要用于预测的线性回归模型。现在需要矩阵乘法来完成这个任务："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Liner Regression Model\n",
    "Y_hat = tf.matmul(X,w) # 两个矩阵相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 为了更好地求微分，定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function tf.reduce_mean\n",
    "# 函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。\n",
    "loss = tf.reduce_mean(tf.square(Y - Y_hat, name='loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 选择正确的优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 定义初始化操作符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "total = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 开始计算图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 450.306884765625\n",
      "Epoch 1: Loss 315.9251403808594\n",
      "Epoch 2: Loss 239.66192626953125\n",
      "Epoch 3: Loss 195.8450164794922\n",
      "Epoch 4: Loss 170.16705322265625\n",
      "Epoch 5: Loss 154.65354919433594\n",
      "Epoch 6: Loss 144.85838317871094\n",
      "Epoch 7: Loss 138.30178833007812\n",
      "Epoch 8: Loss 133.59954833984375\n",
      "Epoch 9: Loss 129.9781951904297\n",
      "Epoch 10: Loss 127.00444030761719\n",
      "Epoch 11: Loss 124.43476867675781\n",
      "Epoch 12: Loss 122.13154602050781\n",
      "Epoch 13: Loss 120.01606750488281\n",
      "Epoch 14: Loss 118.04276275634766\n",
      "Epoch 15: Loss 116.18439483642578\n",
      "Epoch 16: Loss 114.42420196533203\n",
      "Epoch 17: Loss 112.75123596191406\n",
      "Epoch 18: Loss 111.15784454345703\n",
      "Epoch 19: Loss 109.63838958740234\n",
      "Epoch 20: Loss 108.18829345703125\n",
      "Epoch 21: Loss 106.80375671386719\n",
      "Epoch 22: Loss 105.48135375976562\n",
      "Epoch 23: Loss 104.21802520751953\n",
      "Epoch 24: Loss 103.01094055175781\n",
      "Epoch 25: Loss 101.8573989868164\n",
      "Epoch 26: Loss 100.75491333007812\n",
      "Epoch 27: Loss 99.7010498046875\n",
      "Epoch 28: Loss 98.69355773925781\n",
      "Epoch 29: Loss 97.73030853271484\n",
      "Epoch 30: Loss 96.80921936035156\n",
      "Epoch 31: Loss 95.92833709716797\n",
      "Epoch 32: Loss 95.08577728271484\n",
      "Epoch 33: Loss 94.2798080444336\n",
      "Epoch 34: Loss 93.50870513916016\n",
      "Epoch 35: Loss 92.77085876464844\n",
      "Epoch 36: Loss 92.064697265625\n",
      "Epoch 37: Loss 91.3888168334961\n",
      "Epoch 38: Loss 90.74176025390625\n",
      "Epoch 39: Loss 90.12220001220703\n",
      "Epoch 40: Loss 89.52887725830078\n",
      "Epoch 41: Loss 88.96057891845703\n",
      "Epoch 42: Loss 88.41614532470703\n",
      "Epoch 43: Loss 87.89447784423828\n",
      "Epoch 44: Loss 87.39450073242188\n",
      "Epoch 45: Loss 86.91523742675781\n",
      "Epoch 46: Loss 86.4557113647461\n",
      "Epoch 47: Loss 86.01502990722656\n",
      "Epoch 48: Loss 85.5923080444336\n",
      "Epoch 49: Loss 85.18672180175781\n",
      "Epoch 50: Loss 84.7974853515625\n",
      "Epoch 51: Loss 84.42384338378906\n",
      "Epoch 52: Loss 84.0650634765625\n",
      "Epoch 53: Loss 83.72048950195312\n",
      "Epoch 54: Loss 83.38945007324219\n",
      "Epoch 55: Loss 83.0713119506836\n",
      "Epoch 56: Loss 82.7655029296875\n",
      "Epoch 57: Loss 82.4714584350586\n",
      "Epoch 58: Loss 82.18860626220703\n",
      "Epoch 59: Loss 81.91646575927734\n",
      "Epoch 60: Loss 81.65452575683594\n",
      "Epoch 61: Loss 81.40234375\n",
      "Epoch 62: Loss 81.15943908691406\n",
      "Epoch 63: Loss 80.92540740966797\n",
      "Epoch 64: Loss 80.69983673095703\n",
      "Epoch 65: Loss 80.48235321044922\n",
      "Epoch 66: Loss 80.27257537841797\n",
      "Epoch 67: Loss 80.07015228271484\n",
      "Epoch 68: Loss 79.874755859375\n",
      "Epoch 69: Loss 79.68607330322266\n",
      "Epoch 70: Loss 79.5037612915039\n",
      "Epoch 71: Loss 79.32756805419922\n",
      "Epoch 72: Loss 79.1572036743164\n",
      "Epoch 73: Loss 78.99241638183594\n",
      "Epoch 74: Loss 78.83293914794922\n",
      "Epoch 75: Loss 78.67852783203125\n",
      "Epoch 76: Loss 78.52896118164062\n",
      "Epoch 77: Loss 78.38404083251953\n",
      "Epoch 78: Loss 78.24351501464844\n",
      "Epoch 79: Loss 78.10723114013672\n",
      "Epoch 80: Loss 77.97496032714844\n",
      "Epoch 81: Loss 77.84654235839844\n",
      "Epoch 82: Loss 77.72180938720703\n",
      "Epoch 83: Loss 77.60059356689453\n",
      "Epoch 84: Loss 77.48271942138672\n",
      "Epoch 85: Loss 77.3680648803711\n",
      "Epoch 86: Loss 77.25647735595703\n",
      "Epoch 87: Loss 77.14781188964844\n",
      "Epoch 88: Loss 77.04194641113281\n",
      "Epoch 89: Loss 76.93878173828125\n",
      "Epoch 90: Loss 76.8381576538086\n",
      "Epoch 91: Loss 76.73998260498047\n",
      "Epoch 92: Loss 76.64414978027344\n",
      "Epoch 93: Loss 76.5505599975586\n",
      "Epoch 94: Loss 76.4591064453125\n",
      "Epoch 95: Loss 76.36971282958984\n",
      "Epoch 96: Loss 76.28226470947266\n",
      "Epoch 97: Loss 76.19670104980469\n",
      "Epoch 98: Loss 76.1129150390625\n",
      "Epoch 99: Loss 76.03086853027344\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter('graphs', sess.graph)\n",
    "    # train the model for 100 epochs\n",
    "    for i in range(100):  # 迭代100次\n",
    "        _, l = sess.run([optimizer, loss], feed_dict={X: X_train, Y: Y_train})\n",
    "        total.append(l)  # 记录一个轮次的平均loss值\n",
    "        print(\"Epoch {0}: Loss {1}\".format(i, l))\n",
    "    writer.close()\n",
    "    w_value = sess.run([w])  # 获取最后的 b 和 w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 绘制损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20aa4fbf710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total) # 显示 loss 图\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节使用了 13 个特征来训练模型。简单线性回归和多元线性回归的主要不同在于权重，且系数的数量始终等于输入特征的数量。下图为所构建的多元线性回归模\n",
    "型的 TensorBoard 图：\n",
    "<img src=\"./Markdown_images/miao_15_TensorFlow_实现多元线性回归/01.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在可以使用从模型中学到的系数来预测房价："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value:$[23700.] Actual value:/$[16800.]\n"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "X_new = X_train[N,:]\n",
    "Y_pred = (np.matmul(X_new, w_value)).round(1)\n",
    "print('Predicted value:${0} Actual value:/${1}'.format(Y_pred[0]*1000, Y_train[N] * 1000, '\\nDone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
