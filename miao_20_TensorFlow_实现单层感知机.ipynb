{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow实现单层感知机详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单感知机是一个单层神经网络。它使用阈值激活函数，正如 Marvin Minsky 在论文中所证明的，它只能解决线性可分的问题。虽然这限制了单层感知机只能应用于线性可分问题，但它具有学习能力已经很好了。\n",
    "\n",
    "当感知机使用阈值激活函数时，不能使用 TensorFlow 优化器来更新权重。我们将不得不使用权重更新规则：\n",
    "$$\n",
    "\\Delta W = \\eta X ^ { \\mathrm { T } } \\left( Y - Y _ { \\mathrm { hat } } \\right)\n",
    "$$\n",
    "η 是学习率。为了简化编程，当输入固定为 +1 时，偏置可以作为一个额外的权重。那么，上面的公式可以用来同时更新权重和偏置。\n",
    "\n",
    "下面讨论如何实现单层感知机："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 导入所需的模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. 定义要是用的超参数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "eta = 0.4 # learning rate parameter\n",
    "epsilon = 1e-03 # minimum accepted error\n",
    "max_epohs = 100 # Maximum Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 指定训练数据。在这个例子中，取三个输入神经元（A，B，C）并训练它学习逻辑 AB+BC："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Y = AB + BC, sum of two linear functions.\n",
    "T, F = 1.0, 0.0\n",
    "X_in = [[T, T, T, T], [T, T, F, T], [T, F, T, T], [T, F, F, T], [F, T, T, T],\n",
    "        [F, T, F, T], [F, F, T, T], [F, F, F, T]]\n",
    "\n",
    "Y = [[T], [T], [F], [F], [T], [F], [F], [F]]\n",
    "\n",
    "print(X_in)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义要用到的变量和用于计算更新的计算图，最后执行计算图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Activation function\n",
    "def threshold(x):\n",
    "    \"\"\"小于0返回0，否则返回1\"\"\"\n",
    "    cond = tf.less(x, tf.zeros(tf.shape(x), dtype=x.dtype)) # cond： x 元素小于 0 的地方 为 True 否则 为 False\n",
    "    out = tf.where(cond, tf.zeros(tf.shape(x)), tf.ones(tf.shape(x))) # out: cond 为True的地方是 0 是False的地方 是 1 \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([4, 1], stddev=2, seed=0))\n",
    "h = tf.matmul(X_in, w)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = threshold(h)\n",
    "error = Y - Y_hat\n",
    "mean_error = tf.reduce_mean(tf.square(error))\n",
    "dW = eta * tf.matmul(X_in, error, transpose_a=True)\n",
    "train = tf.assign(w, w + dW)\n",
    "\n",
    "\n",
    "err = 1\n",
    "epoch = 0\n",
    "while err > epsilon and epoch < max_epohs:\n",
    "    epoch += 1\n",
    "    err, _ = sess.run([mean_error, train])\n",
    "    print('epoch:{0} mean error:{1}'.format(epoch, err))\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，如果使用 Sigmoid 激活函数，而不是阈值激活函数，会发生什么？你猜对了，首先，可以使用 TensorFlow 优化器来更新权重。其次，网络将表现得像逻辑回归。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
